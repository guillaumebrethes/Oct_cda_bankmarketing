import streamlit as st  # type: ignore
import pandas as pd
import numpy as np
import joblib # type: ignore
import matplotlib.pyplot as plt
from streamlit_shap import st_shap # type: ignore
import shap # type: ignore
import plotly.graph_objects as go # type: ignore
import matplotlib.colors as mcolors

# Page
st.set_page_config(
    page_title="Bank Marketing",
    page_icon="üí°", 
    #layout="wide" 
)

# CSS - - - - - 
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
local_css("styles.css")
# - - - - - - - 

# titre
st.markdown('<h1 class="custom-title">Interpr√©tation des mod√®les</h1>', unsafe_allow_html=True)

if st.button("‚óÄÔ∏è\u2003‚öôÔ∏è Modelisation"):
    st.switch_page("pages/4_‚öôÔ∏è_Modelisation.py")
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)

lien_methodeShap = "https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html"


st.markdown(
    f""" Pour compl√©ter l'analyse de la performance des mod√®les, nous allons interpr√©ter la fa√ßon dont les mod√®les pr√©disent en utilisant la m√©thode <a href="{lien_methodeShap}" class="orange-bold">SHAP (SHapley Additive exPlanations)</a>. """, unsafe_allow_html=True
)

# --------------------------------------------------------------------------------------------
# Importation des jeux d'entrainement et de test sauvegard√©s  depuis google collab
X_test = pd.read_csv("Split_csv/3_bank_X_test.csv",index_col=0)
y_test = pd.read_csv("Split_csv/3_bank_y_test.csv",index_col=0)
X_test_copie = pd.read_csv("Split_csv/3_bank_X_test_copie.csv",index_col=0)

#Importation des valeurs Shap (que la classe 1 pour rfc)
shap_values_gbc = np.load('Shap/shap_values_gbc.npy')
shap_values_rfc = np.load('Shap/shap_values_rfc.npy')

# importations des mod√®les optimis√©s √† interpr√©ter
gbc_after = joblib.load("Models/model_gbc_after")
rfc_after = joblib.load("Models/model_rfc_after")
# --------------------------------------------------------------------------------------------

st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.markdown("<h3 class='titre-h3'>Interpr√©tation des Mod√®les avec la m√©thode SHAP</h3>", unsafe_allow_html=True)

# st.markdown('<h1 style="font-size: 30px;">Interpr√©tation des Mod√®les avec la m√©thode SHAP</h1>', unsafe_allow_html=True)

#---------------------------------------
#Cr√©ation d'un expander pour expliquer la m√©thode Shap

with st.expander("Cliquez ici pour en savoir plus sur la m√©thode SHAP"):

    st.markdown("""
    <div class="explain_shap">
        La m√©thode SHAP (SHapley Additive exPlanations) repose sur les valeurs de Shapley, une m√©thode issue de la th√©orie des jeux coop√©ratifs, pour attribuer √† chaque caract√©ristique (ou variable) une importance en fonction de sa contribution √† la pr√©diction.
        <br><br>
        SHAP est une m√©thode qui explique comment les pr√©dictions individuelles sont effectu√©es par un mod√®le d'apprentissage automatique. Elle d√©construit une pr√©diction en une somme de contributions (valeurs SHAP) de chacune des variables d'entr√©e du mod√®le.
        <br><br>
        √Ä noter que SHAP indique ce que fait le mod√®le dans le contexte des donn√©es sur lesquelles il a √©t√© form√©. Il ne r√©v√®le pas n√©cessairement la v√©ritable relation entre les variables et les r√©sultats dans le monde r√©el.
    </div>
    """, unsafe_allow_html=True)
    
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
#----------------------------------------------------------------------------------------------------------------------
#On propose de voir la page en fonction du mod√®le s√©l√©ctionn√© gbc_after ou rfc_after

st.markdown("""
Bienvenue dans cette application d'analyse des mod√®les ! Vous pouvez s√©lectionner un mod√®le dans la liste d√©roulante ci-dessous pour visualiser les 10 variables les plus importantes.
""")

# S√©lection du mod√®le via liste d√©roulante
model_choice = st.selectbox(
    label='',
    options=['Gradient Boosting Classifier', 'Random Forest Classifier'], 
    index=None, 
    placeholder="Mod√®le . . .")
# ------------------------------------------

# Graphique d'importance des variables
if model_choice:
    model = gbc_after if model_choice == 'Gradient Boosting Classifier' else rfc_after
    shap_values = shap_values_gbc if model_choice == 'Gradient Boosting Classifier' else shap_values_rfc
    expected_value = shap.TreeExplainer(gbc_after).expected_value \
    if model_choice == 'Gradient Boosting Classifier'\
        else shap.TreeExplainer(rfc_after).expected_value[1]

   # Cr√©ez la figure avec un fond transparent
    fig = plt.figure()
    fig.patch.set_alpha(0)  # Rendre le fond de la figure transparent
   
   # G√©n√©rer le graphique SHAP de type "bar"
    shap.summary_plot(shap_values, X_test, plot_type="bar", max_display=10, show=False, color='#ADD8E6')
   
   # Rendre le fond des axes transparent
    ax = plt.gca()
    ax.patch.set_alpha(0)
   
   # Afficher le graphique avec Streamlit en utilisant un fond transparent
    plt.gcf().set_facecolor('none')
    st.pyplot(plt.gcf(), use_container_width=True)

    st.markdown(
        """
        L'axe des X repr√©sente la moyenne des valeurs SHAP absolues pour chaque variable, indiquant l'importance moyenne de chaque variable sur la pr√©diction du mod√®le. **`duration`**  est la variable qui influence le plus la pr√©diction du mod√®le.
        """, unsafe_allow_html=True)

# Utilisation d'un extender pour montrer le Graphique d'importance des variables     
    with st.expander("üîç **Impact des variables dans la d√©cision du mod√®le**"):
        fig = plt.figure()
        fig.patch.set_alpha(0)  # Rendre le fond de la figure transparent
        
        # D√©finir la colormap personnalis√©e
        cmap = mcolors.LinearSegmentedColormap.from_list("", ["#ADD8E6", "#F08080"])
      
        # G√©n√©rer le graphique SHAP
        shap.summary_plot(shap_values, X_test, max_display=10, show=False, cmap=cmap)
        
        # Rendre le fond des axes transparent
        ax = plt.gca()
        ax.patch.set_alpha(0)
        
        # Afficher le graphique avec Streamlit en utilisant un fond transparent
        plt.gcf().set_facecolor('none')
        st.pyplot(plt.gcf(), use_container_width=True)
         
        st.markdown(
            """
            Dans ce graphique, l'axe des x repr√©sente la valeur SHAP et l'axe des y repr√©sente les variables explicatives (ici le TOP 10). Chaque point du graphique correspond √† une valeur SHAP pour une pr√©diction et une variable explicative. 
            
            La couleur rouge signifie une valeur plus √©lev√©e de la variable explicative. Le bleu signifie une valeur faible de cette derni√®re. Nous pouvons avoir une id√©e g√©n√©rale de la directionnalit√© de l'impact des variables en fonction de la distribution des points rouges et bleus. 
            
            
            On peut lire que plus la valeur de **`duration`** est grande (temps de l'appel long), plus l'impact sur la pr√©diction de souscription du d√©p√¥t √† terme est positif  et inversement plus **`duration`** est faible, plus l'impact sur la pr√©diction est n√©gatif.
            
            Une valeur importante de **`poutcome_success`** (client avait souscrit √† un d√©p√¥t √† terme auparavant) a un impact positif sur la souscription du d√©p√¥t √† terme.
            
            Une valeur plus grande de **`housing`** (le client a un pr√™t immobilier) a un impact n√©gatif sur la pr√©diction de la souscription du d√©p√¥t et inversement une valeur faible ( le client n‚Äôa pas de pr√™t immobilier) a un effet positif sur la pr√©diction de la souscription du d√©p√¥t.
            """, unsafe_allow_html=True)

#---------------------------------------
# Utilisation d'un extender pour montrer les predictions et shap values par individu
    with st.expander("üîç **Visualisation des pr√©dictions individuelles du jeux de donn√©es Test**"):
    
    # Choix de l'index par l'utilisateur 743 est cool
        index_to_show = st.slider('Choisissez l\'index de l\'observation √† visualiser', 0, len(X_test) - 1, 0, 
                              help = "les cases coch√©es repr√©sentent le mois, le job, le poutcome du client selectionn√©")

    # Cr√©er un objet Explanationx
        shap_values_instance = shap.Explanation(
            values=shap_values[index_to_show],
            base_values=expected_value,
            data=X_test.iloc[index_to_show]  # Inclure les donn√©es d'entr√©e pour plus de contexte dans le plot
    )

    #Afficher les informations du DataFrame pour cet infividu
        st.dataframe(X_test_copie.iloc[[index_to_show]])

    # Afficher (y_test) ---
        if y_test.iloc[index_to_show].item()== 1:
            deposit = "**a souscrit au d√©p√¥t √† terme.**"
        else:
            deposit = "**n'a pas souscrit au d√©p√¥t √† terme.**"
        st.markdown(f"<span class='orange-bold'>D√©cision r√©elle du client</span> : Cet individu <span style='font-weight:bold; color:black;'>{deposit}</span>", unsafe_allow_html=True)
    # ---
    
    # Afficher ((y_pred) ---
        y_pred = model.predict(X_test.iloc[[index_to_show]])
        if y_pred.item() == 1:
           deposit_pred = " **souscrira au d√©p√¥t √† terme.**"
        else:
            deposit_pred = "**ne souscrira pas au d√©p√¥t √† terme.**"
        st.markdown(f"<span class='orange-bold'>Pr√©diction du mod√®le</span> : Ce mod√®le pr√©dit que cet individu <span style='font-weight:bold; color:black;'>{deposit_pred}</span>", unsafe_allow_html=True)
    # ---

    #Afficher les valeurs shap (top 10 pour cet individu)
        st.markdown("<span class='orange-bold'>Waterfall plot</span> pour cet individu :", unsafe_allow_html=True)
        # Create a figure with transparent background
        fig, ax = plt.subplots()
        fig.patch.set_alpha(0.0)
        ax.patch.set_alpha(0.0)
        
        # Generate the waterfall plot on the created figure
        shap.plots.waterfall(shap_values_instance, max_display=10, show=False)
        
        # Display the plot in Streamlit
        st.pyplot(fig)
   #Explications de lecture du graphique
   
           #Explications de lecture du graphique
           
        st.markdown(
        """
        La structure en cascade illustre comment les **`contributions additives des variables explicatives`** , qu'elles soient positives ou n√©gatives, s'accumulent √† partir d'une valeur de base (E[f(X)]). 
        
        Cette accumulation met en √©vidence comment chaque variable explicative construit progressivement la pr√©diction finale du mod√®le, not√©e f(x).
        """
        ) 

#---------------------------------------

    with st.expander("üîç **Impact des variables dans la pr√©diction en fonction de leur valeur**"):
    
        st.markdown("""Gr√¢ce au <span class="orange-bold">Dependance plot</span> on peut visualiser et comprendre comment des valeurs sp√©cifiques d'une variable influencent les pr√©dictions du mod√®le.""", unsafe_allow_html=True)
            
        # Fonction pour afficher le graphique de d√©pendance SHAP
        def plot_dependence_plot(selected_var, shap_values, X_test_copie, fig_width=4, fig_height=3):
            plt.figure(figsize=(fig_width, fig_height), facecolor='none')
            shap.dependence_plot(selected_var, shap_values, X_test_copie, interaction_index=None, color='#ADD8E6', show=False)
            ax = plt.gca() 
            ax.patch.set_alpha(0)
            plt.gcf().set_facecolor('none')
            st.pyplot(plt)

        # Liste des variables √† afficher dans le multiselect
        variables = ['duration', 'balance', 'age', 'campaign']

        # Affichage du multiselect
        selected_variables = st.multiselect("S√©lectionnez les variables √† afficher :", variables)

        # Affichage des graphiques pour les variables s√©lectionn√©es
        for var in selected_variables:
            st.markdown(f"""<span style="font-size: 20px; font-weight: bold; color: #E97132; text-decoration: underline;">Graphique de D√©pendance SHAP pour la Variable **`{var}`**</span>""", unsafe_allow_html=True)
            if var=='balance':
                st.markdown("""<span class="orange-bold">balance</span> est le solde moyen annuel sur le compte courant.""", unsafe_allow_html=True)
            elif var=='campaign':
                st.markdown("""<span class="orange-bold">campaign</span> est le nombre de contacts effectu√©s sur la campagne.""", unsafe_allow_html=True)
            
            plot_dependence_plot(var, shap_values, X_test_copie, fig_width=3, fig_height=2)
            
            if var == 'duration':
                st.markdown("""On peut voir √† partir de quelle valeur de **`duration`** l'impact sur la pr√©diction devient positif.""", unsafe_allow_html=True)
            elif var=='balance':
                st.markdown("""On peut voir √† partir de quelle valeur de **`balance`** l'impact sur la pr√©diction devient positif.""", unsafe_allow_html=True)
            elif var=='age':
                st.markdown("""On peut voir les **`√¢ges`** pour lesquels l'impact sur la pr√©diction est positif et ceux pour lesquels l'impact est n√©gatif.""", unsafe_allow_html=True)
            elif var=='campaign':
                st.markdown("""On peut voir que s'il y a plus d'1 contact, **`campaign`** a un impact n√©gatif sur la pr√©vision.""", unsafe_allow_html=True)
            st.markdown("---")    

# ------------------------------------------------------------------------------------------------
# bouton de basculement de page 
st.write("   ")
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.write("   ")

if st.button("‚ñ∂Ô∏è\u2003 üéØ Recommandation m√©tier - Conclusion"):
    st.switch_page("pages/6_üéØ_Recommandation_m√©tier_-_Conclusion.py")
    

# ------------------------------------------------------------------------------------------------
