import streamlit as st  # type: ignore
from streamlit_shap import st_shap # type: ignore
import pandas as pd
import numpy as np
import joblib # type: ignore
import matplotlib.pyplot as plt
import seaborn as sns # type: ignore
import shap # type: ignore
import plotly.graph_objects as go # type: ignore
import plotly.express as px # type: ignore
from sklearn.metrics import classification_report # type: ignore
from sklearn.metrics import confusion_matrix # type: ignore
from sklearn.metrics import roc_curve, roc_auc_score # type: ignore


# Page
st.set_page_config(
    page_title="Bank Marketing",
    page_icon="‚öôÔ∏è", 
    #layout="wide" 
)

# CSS - - - - - 
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
local_css("styles.css")
# - - - - - - - 

st.markdown('<h1 class="custom-title">Mod√©lisation</h1>', unsafe_allow_html=True)
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)


if st.button("‚óÄÔ∏è\u2003üìä Visualiation - Statistique"):
    st.switch_page("pages/3_üìä_Visualiation_-_Statistique.py")
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.markdown(
    """ 
    Nous exposons ici notre travail de mod√©lisation. Nous allons effecter le pr√©traitement des donn√©es, choisir une m√©trique de performance, entra√Æner et ajuster des mod√®les. Pour finir, nous pr√©senterons l'analyse des mod√®les les plus performants.
    """
    )

# --------------------------------------------------------------------------------------------

df=pd.read_csv("bank.csv") #jeu de donn√©es initial
dfclean=pd.read_csv("2_bank_clean.csv")#jeu de donn√©es nettoy√© et encod√©

#r√©sultats de tous les mod√®les entrain√©s
df_tableau_diff_analyse = pd.read_csv("Tableau_des_diff√©rentes_analyses.csv", sep=";")

#gbc et rfc param√®tres before & after
params_gbc_before_df = pd.read_csv("Models/params_gbc_before.csv", sep=",")
params_gbc_after_df = pd.read_csv("Models/params_gbc_after.csv", sep=",")
params_rfc_before_df = pd.read_csv("Models/params_rfc_before.csv", sep=",")
params_rfc_after_df = pd.read_csv("Models/params_rfc_after.csv", sep=",")


# Importation des jeux d'entrainement et de test sauvegard√©s  depuis google collab
X_test = pd.read_csv("Split_csv/3_bank_X_test.csv",index_col=0)
y_test = pd.read_csv("Split_csv/3_bank_y_test.csv",index_col=0)
X_train= pd.read_csv("Split_csv/3_bank_X_train.csv",index_col=0)
y_train= pd.read_csv("Split_csv/3_bank_y_train.csv",index_col=0)
X_test_copie = pd.read_csv("Split_csv/3_bank_X_test_copie.csv",index_col=0)

#Importation des valeurs Shap (que la classe 1 pour rfc)
shap_values_gbc = np.load('Shap/shap_values_gbc.npy')
shap_values_rfc = np.load('Shap/shap_values_rfc.npy')

# importations des mod√®les optimis√©s √† interpr√©ter
gbc_after = joblib.load("Models/model_gbc_after")
rfc_after = joblib.load("Models/model_rfc_after")

# importations des mod√®les avant optimisation
gbc_before = joblib.load("Models/model_gbc_before")
rfc_before = joblib.load("Models/model_rfc_before")

# importations des grilles de param√®tre utilis√©es dand GriSearchCV()
gbc_param_grid_df = pd.read_csv('Models/gbc_param_grid.csv')
rfc_param_grid_df = pd.read_csv('Models/rfc_param_grid.csv')

# --------------------------------------------------------------------------------------------

# PRE PROCESSING

st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.markdown("<h3 class='titre-h3'>Pr√© Processing</h3>", unsafe_allow_html=True)


with st.expander("Cliquez ici pour en savoir plus sur la Transformation du Data Frame pour l'√©tape de machine Learning"):
    
# Gestion des Outliers
    if st.checkbox("Gestion des Valeur Extr√™mes", key='checkbox1'):
        st.markdown("Il n'y a aucune valeurs extr√™mes qui semblent ab√©rentes dans nos variables qualitatives. Cependant nous devons traiter les valeurs extr√™mes pour √©viter les perturbations sur nos mod√®les de Machine Learning.")
        st.markdown(
            """ 
            **`Nous appliquons la m√©thode "IQR":`**  
            on supprime les valeurs qui se trouvent en dehors de l'intervalle "Inter Quartile Range", c'est √† dire :
            - les valeurs sup√©rieures √† [ Q3 + 1.5 x (Q3 - Q1)]
            - les valeurs inf√©rieures √† [Q1 - 1.5 x (Q3 - Q1)]  
            avec Q1 le premier quartile et Q3 le troisi√®me quartile
            """, unsafe_allow_html=True)
        
        st.write("Nous avons supprim√©", round((100 - (dfclean.shape[0] * 100) / df.shape[0]), 2), "*%* des lignes de notre dataframe initial", "cependant il nous reste encore :", dfclean.shape[0], "lignes (clients) pour l'√©tape de mod√©lisation.")
        
        def plot_box(df, column, fig_width=600, fig_height=300, color='skyblue', title_suffix=""):
            # Cr√©er le graphique Boxplot avec Plotly
            fig = px.box(df, x=column, hover_data=df.columns)
        
            # Mise √† jour de la mise en page
            fig.update_layout(
                title=f"<b>Boxplot de '{column}' {title_suffix}</b>",
                width=fig_width,
                height=fig_height,
                font_family="Arial",  # Harmonisation de la police
                title_font_family="Arial",
                paper_bgcolor='rgba(0,0,0,0)',  # Fond transparent
                plot_bgcolor='rgba(0,0,0,0)',  # Fond transparent
                xaxis_title=f"<b style='color:black; font-size:90%;'>{column}</b>",
                yaxis_title="<b style='color:black; font-size:90%;'>Valeur</b>"
            )
        
           # Mise √† jour des traces
            fig.update_traces(
                marker=dict(
                  color=color,  # Couleur du remplissage
                  line=dict(color='gray', width=1)  # Couleur de la bordure des points et son √©paisseur
              ),
              boxpoints='outliers'  # Afficher uniquement les points aberrants (outliers)
          )
        
            # Affichage du graphique dans Streamlit
            st.plotly_chart(fig, use_container_width=True)

# Exemple d'utilisation de la fonction (remarque : assurez-vous que 'df' et 'column' sont d√©finis dans votre script)
# plot_box(df, 'some_column_name', title_suffix="quelque chose")
        
        

   # Liste des variables pour lesquelles on veut voir les boxplots avec une option initiale
        variables = ['age', 'balance', 'duration', 'campaign']
        selected_var = st.selectbox(
            "Choisir une variable pour afficher les bo√Ætes √† moustache avant et apr√®s suppression des valeurs extr√™mes:", 
            options = variables,
            index = None,
            placeholder = "Variables . . .")

    # V√©rification si une variable a √©t√© s√©lectionn√©e et n'est pas l'option initiale
        if selected_var :
            plot_box(df, 
                     selected_var, 
                     fig_width=600, 
                     fig_height=300, 
                     color='lightcoral', 
                     title_suffix="avant supression des valeurs extr√™mes")
    
            plot_box(dfclean, 
                     selected_var, 
                     fig_width=600, 
                     fig_height=300, 
                     color='lightcoral', 
                     title_suffix="apr√®s suppression des valeurs extr√™mes")

# Encodage des variables
    if st.checkbox("Encodage des variables", key='checkbox2'):
   
        # Variables Binaires 
        st.markdown("<strong class='type-de-variables'>üóÇÔ∏è Variables Binaires</strong>", unsafe_allow_html=True)
        st.markdown(
            """
            - Les modalit√©s **`yes`** et **`no`** des variables **`default`**, **`housing`**, **`loan`**, **`deposit`** seront donc remplac√©es respectivement par **`1`** et **`0`**
            - Nous avons arbitrairement remplac√© la modalit√© **`-1`** de **`pdays`**  par **`0`**, pour faciliter la compr√©hension d'un point de vue m√©tier. En effet, si il n'y a pas eu de contact depuis la pr√©c√©dente campagne marketing, la valeur la plus adapt√©e semble √™tre **`0`**
            """
            )
        
        # Variables ordinales 
        st.markdown("<strong class='type-de-variables'>üóÇÔ∏è Variables ordinales</strong>", unsafe_allow_html=True)

        st.markdown("- La seule variable ordinale dans le jeu de donn√©es est **`education`**. Nous d√©cidons de remplacer les modalit√©s : **`primary`**, **`secondary`** et **`tertiary`**, respectivement par **`0`**, **`1`** et **`2`**.")
        
        # Variables non-ordinales
        st.markdown("<strong class='type-de-variables'>üóÇÔ∏è Variables non-ordinales</strong>", unsafe_allow_html=True)
        st.markdown(
            """
            - Pour les variables **`job`**, **`marital`**, **`month`**, **`poutcome`** qui sont non-ordinales, nous allons appliquer la m√©thode **`get.dummies()`**, pour effectuer une dichotomisation.
            - Avant cela, nous avons bien √©videmment s√©par√© notre variable cible **`y (deposit)`** de notre jeu de donn√©es **`X`**. Nous avons r√©alis√© un split entre le jeu d'entra√Ænement **` X_TRAIN (80%)`** et le jeu test **`X_TEST (20%)`**. 
            """
            )

        st.write("‚û°Ô∏è la taille de notre df initial est de :",df.shape)
        st.write("‚û°Ô∏è la taille de notre df X_train est de :", X_train.shape)
        st.write("‚û°Ô∏è la taille de notre df X_test est de :", X_test.shape)
    

# Standardisation des donn√©es   

    if st.checkbox("Standardisation des donn√©es", key='checkbox3'):
        lien_standartScaller = "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
        
        st.markdown(
            f"""
            Nous utilisons <a href="{lien_standartScaller}" class="orange-bold">StandardScaler()</a>, qui nous permet de r√©aliser une mise √† l'√©chelle en soustrayant la moyenne et en divisant par l'√©cart type, de sorte que les valeurs aient une moyenne de z√©ro, et un √©cart type de 1.
            """, unsafe_allow_html=True)

        

#--------------------------------------------------------------------------------------------
  
  
#MODELISATION

st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.markdown("<h3 class='titre-h3'>S√©lection et Optimisation des Mod√®les</h3>", unsafe_allow_html=True)

# st.markdown('<h1 style="font-size: 30px;">Interpr√©tation des Mod√®les avec la m√©thode SHAP</h1>', unsafe_allow_html=True)

#Synth√®se des √©tapes de mod√©lisation et pr√©sentation du tableau de r√©sultats
with st.expander("Cliquez ici pour en savoir plus sur les √©tapes de la mod√©lisation"):

    st.markdown(
        """<strong class='type-de-variables'>üìù Probl√©matique</strong> 
                
Ce projet s'apparente √† une t√¢che de machine learning appel√©e **`la classification supervis√©e`**. La classification consiste √† pr√©dire si un client (**la variable √† pr√©dire**) acceptera (**classe 1**) ou non (**classe 0**) de souscrire √† un d√©p√¥t bancaire en utilisant les donn√©es disponibles sur ce client.
""", unsafe_allow_html=True)

    st.markdown(
        """ <strong class='type-de-variables'>üìè M√©trique</strong>

Nous choisissons le **`Recall de la classe 1`** (Rappel) comme m√©trique cl√© dans **l'√©valuation** de nos mod√®les.  
‚ÜóÔ∏è Maximiser les **Vrais positifs** (identifications correctes de clients potentiels qui sont tr√®s susceptibles de souscrire √† l'offre)  
‚ÜòÔ∏è Minimiser les **Faux N√©gatifs** (le nombre de ces clients potentiels que le mod√®le pourrait manquer)
""", unsafe_allow_html=True)

    lien_GridSearchCV = "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"



    st.markdown(
        f""" <strong class='type-de-variables'>‚öôÔ∏è M√©thode d'optimisation des hyperparam√®tres</strong>
          
Nous utilisons <a href="{lien_GridSearchCV}"> GridSearchCV()</a> pour trouver la combinaison optimale des param√®tres des mod√®les.
""", unsafe_allow_html=True)

    st.markdown("""<strong class='type-de-variables'>
‚úîÔ∏è Mod√®les entrain√©s et optimis√©s</strong><br>
  1Ô∏è‚É£ Random Forest Classifier<br>
  2Ô∏è‚É£ Gradiant Boosting Classifier<br>
  3Ô∏è‚É£ Decision Tree Classifier<br>
  4Ô∏è‚É£ SVM Classifier<br>
  5Ô∏è‚É£ Regression<br>

""", unsafe_allow_html=True)

    
        # Initialisation des variables d'√©tat si elles n'existent pas d√©j√†
    if 'show_table' not in st.session_state:
        st.session_state.show_table = False
    if 'show_visualization' not in st.session_state:
        st.session_state.show_visualization = False
  
#Bouton de visualisation des r√©sultas
    # D√©finition des boutons
    if st.button("üìä Visualisation des r√©sultats", key='button5'):
        st.session_state.show_visualization = not st.session_state.show_visualization
    
    # Condition pour afficher ou non la visualisation des r√©sultats
    if st.session_state.show_visualization:
      
        # Filtrer les donn√©es par "par d√©faut" et "personnalis√©"
        default = df_tableau_diff_analyse[df_tableau_diff_analyse['Hyper parametres'] == 'par d√©faut']
        custom = df_tableau_diff_analyse[df_tableau_diff_analyse['Hyper parametres'] == 'Optimis√©']
        
        # Cr√©er un DataFrame pour Plotly
        df_plotly = pd.concat([
            default.assign(HyperParam="Par d√©faut"),
            custom.assign(HyperParam="Optimis√©")
        ])
        
        # Ajouter la colonne de pourcentage pour les √©tiquettes de texte
        df_plotly['Recall % class 1'] = df_plotly['Recall % class 1'] 
        df_plotly['percent'] = df_plotly['Recall % class 1'].apply(lambda x: '{}%'.format(round(x, 1)))
        
        # Cr√©er le graphique √† barres avec Plotly Express
        fig = px.bar(df_plotly, x='Mod√®les', y='Recall % class 1', text='percent', color='HyperParam',
                     barmode='group', color_discrete_sequence=['lightcoral', 'lightblue'],
                     width=600, height=450)
        
        # Mettre √† jour les traces
        fig.update_traces(marker=dict(line=dict(color='#000000', width=1)), textposition="outside")
        
        # Mettre √† jour la mise en page de la figure
        fig.update_layout(
            showlegend=True,
            title_text='<b style="color:black; font-size:90%;">Comparaison des mod√®les par d√©faut et Optimis√©s sur Recall % class 1</b>',
            font_family="Arial",
            title_font_family="Arial",
            xaxis_title='<b style="color:black; font-size:90%;">Mod√®les</b>',
            yaxis_title='<b style="color:black; font-size:90%;">Recall % class 1</b>',
            yaxis=dict(range=[0, 110]),  # Ajuster l'axe des ordonn√©es
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
 )
        # Afficher le graphique dans Streamlit
        st.plotly_chart(fig, use_container_width=True)
        
  
#Bouton D√©tail des r√©sultats(Tableau)
    if st.button("ùÑú Tableau D√©taill√© des r√©sultats", key='button4'):
        st.session_state.show_table = not st.session_state.show_table
    
    # Condition pour afficher ou non le tableau des r√©sultats
    if st.session_state.show_table:
        # Afficher les lignes s√©lectionn√©es du DataFrame
        cols_to_format = [
            "% Score Train",
            "% Score Test",
            "Recall % class 0",
            "Recall % class 1"
        ]
    
        # Appliquer le formatage
        df_tableau_diff_analyse_style = df_tableau_diff_analyse.style.format({col: "{:.2f}" for col in cols_to_format})
        
        # Afficher le DataFrame mis en forme
        st.write(df_tableau_diff_analyse_style)




# ----------------------------------------------------------------------
#ANALYSE APPROFONDIE DES TOPS MODELES

st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.markdown("<h3 class='titre-h3'>Analyse Approfondie des Top Mod√®les</h3>", unsafe_allow_html=True)

# st.markdown('<h1 style="font-size: 30px;">Interpr√©tation des Mod√®les avec la m√©thode SHAP</h1>', unsafe_allow_html=True)

#On propose de voir la page en fonction du mod√®le s√©l√©ctionn√© gbc_after ou rfc_after

st.markdown("""
Bienvenue dans cette application d'analyse des mod√®les ! Vous pouvez s√©lectionner un mod√®le dans la liste d√©roulante ci-dessous pour d√©couvrir ses d√©tails.
""")

#Fonction qui englobe tout le display en fonction du mod√®le choisi
def display_model_analysis(model, title, description=False, parameters=False, performance=False):
    # st.header(title)
    
    if description:
        if title == "Gradient Boosting Classifier":
            lien_GBC = "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
                   
            st.markdown(f"""
            <a href="{lien_GBC}">Le Gradient Boosting Classifier (GBC)</a> est une technique d'apprentissage automatique utilis√©e dans les probl√®mes de classification. Il s'agit d'une m√©thode d'ensemble o√π plusieurs mod√®les d'apprentissage faibles sont combin√©s pour former un mod√®le plus puissant.
            
            1. **`Initialisation`** : le mod√®le commence souvent par cr√©er un arbre de d√©cision peu profond, qui estime la classe cible.
            2. **`Calcul de l'erreur`** : Ensuite, le mod√®le calcule l‚Äôerreur entre sa pr√©diction et la vraie valeur cible.
            3. **`R√©duction de l'erreur`** : L'objectif du Gradient Boosting Classifier est de r√©duire au maximum cette erreur, aussi appel√©e r√©sidu, √† l'aide de la technique de descente de gradient.
            4. **`Mise √† jour des pr√©dictions`** : Les pr√©dictions de ce nouveau mod√®le sont ajout√©es aux pr√©dictions pr√©c√©dentes avec un certain facteur d'apprentissage (learning rate). Ainsi, chaque mod√®le corrige les erreurs r√©siduelles du mod√®le pr√©c√©dent.
            5. **`R√©p√©tition`** : Ce processus est r√©p√©t√© plusieurs fois, chaque it√©ration ajoutant un nouveau mod√®le qui se concentre sur les erreurs restantes des mod√®les pr√©c√©dents.
            6. **`Arr√™t`** : Le mod√®le s'arr√™te soit sur un nombre fixe d'it√©rations, soit lorsque la performance sur un ensemble de validation cesse de s'am√©liorer, ou selon d'autres crit√®res d√©finis par l'utilisateur.
            """, unsafe_allow_html=True)
        
        else:
            lien_RFC = "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
            
            
            st.markdown(f"""
            <a href="{lien_RFC}">Le Random Forest Classifier (RFC)</a> est une technique d'apprentissage automatique utilis√©e pour les probl√®mes de classification. C'est une m√©thode d'ensemble bas√©e sur des arbres de d√©cision.
            
            1. **`Construction des arbres de d√©cision`** : Plusieurs arbres de d√©cision sont construits de mani√®re al√©atoire - Les √©chantillons sont tir√©s avec remise, ce qui signifie qu‚Äôun m√™me client peut √™tre pr√©sent dans plusieurs arbres - Cela am√©liore la robustesse du mod√®le.
            
            2. **`Pr√©diction par vote √† la majorit√©`**  : Une fois tous ces arbres cr√©√©s, la pr√©diction est r√©alis√©e √† l‚Äôaide d‚Äôun vote √† la majorit√© - La classe qui obtient le plus grand nombre de votes devient la pr√©diction finale (0 ou 1) du Random Forest.
            
            3. **`Attention au surentra√Ænement`** : Il est important de noter que ce genre de mod√®le est sensible au surentra√Ænement.
            """, unsafe_allow_html=True)

    # if parameters:
    #     st.write('')
        
        
    if performance:
        
        # Affichage des scores
        
        st.write('')
        train_score = "{:.2f}".format(model.score(X_train, y_train))
        test_score = "{:.2f}".format(model.score(X_test, y_test))
        st.write(f"**Score** sur ensemble **train** &nbsp;&nbsp;&nbsp;&nbsp;**`{train_score}`**")
        st.write(f"**Score** sur ensemble **test** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**`{test_score}`**")
        st.write('')
        st.write('')     
        
        
        # Pr√©diction et rapport de classification   
        
        y_pred = model.predict(X_test)
        report = classification_report(y_test, y_pred)
        st.code(f"Rapport de classification :\n{report}")
        st.write('')
        st.write('')        
        
        
        # Matrice de confusion sous forme de DataFrame (heatmap ne marche pas...)  
        
        conf_matrix = confusion_matrix(y_test, y_pred)
        all_classes = np.array([0, 1])
        df_conf_matrix = pd.DataFrame(conf_matrix, index=[f'Classe {cls}' for cls in all_classes], columns=[f'Pr√©diction Classe {cls}' for cls in all_classes])
        
        # Fonction pour appliquer le style conditionnel
        def highlight_class(val):
            color = ''
            if val == conf_matrix[1, 1]:
                color = 'orange'
            elif val == conf_matrix[1, 0]:
                color = 'blue'
            return f'color: {color}'
        
        # Appliquer le style conditionnel
        styled_df = df_conf_matrix.style.applymap(highlight_class)
        
        # Afficher le DataFrame dans Streamlit
        st.write("Matrice de Confusion")
        st.dataframe(styled_df)
        st.write('') 
        st.write('') 


#Texte enregistr√© pour les checkbox Pr√©sentation des param√®tres utilis√©s

description_hyper_gbc = """
- **`criterion`** : Crit√®re de mesure de qualit√© de la s√©paration des arbres de d√©cision dans le processus de boosting.
    - **friedman_mse** : Utilise l'erreur quadratique moyenne am√©lior√©e de Friedman, qui prend √©galement en compte le gradient de la fonction de perte.
    - **squared_error** : Utilise simplement l'erreur quadratique moyenne, sans tenir compte du gradient. C'est plus rapide √† calculer, mais potentiellement moins pr√©cis.                    
             
- **`learning_rate`** : Taux d'apprentissage, qui contr√¥le la contribution de chaque arbre au mod√®le global. Une valeur plus faible donne une meilleure g√©n√©ralisation, mais n√©cessite plus d'arbres dans l'ensemble.
- **`max_depth`** : Profondeur maximale de chaque arbre dans l'ensemble. Une profondeur plus grande permet au mod√®le de capturer des relations plus complexes dans les donn√©es, mais peut conduire √† un surajustement si elle n'est pas r√©gularis√©e.
- **`min_samples_split`** : Nombre minimum d'√©chantillons requis pour scinder un n≈ìud interne. Cela r√©gule la croissance de l'arbre en imposant des contraintes sur le nombre d'observations n√©cessaires pour former une nouvelle division.
- **`n_estimators`** : Nombre d'arbres dans l'ensemble. Un nombre plus √©lev√© d'arbres peut am√©liorer les performances du mod√®le, mais cela n√©cessite √©galement plus de temps de calcul.
- **`max_features`** : Nombre maximum de caract√©ristiques √† consid√©rer lors de la recherche de la meilleure division. Limiter le nombre de caract√©ristiques peut aider √† r√©duire la variance et le temps de calcul, en particulier dans les ensembles de donn√©es avec de nombreuses fonctionnalit√©s.
- **`subsample`** : Fraction des √©chantillons √† utiliser pour l'entra√Ænement de chaque arbre. Utiliser un sous-ensemble al√©atoire des donn√©es pour chaque arbre peut aider √† r√©duire la variance et √† am√©liorer la g√©n√©ralisation.
"""
 
description_hyper_rfc = """
- **`criterion`** : Crit√®re de mesure de qualit√© de la s√©paration des arbres de d√©cision dans le processus de boosting.
    - **gini** : Utilise l'indice de Gini pour √©valuer la puret√© des n≈ìuds de s√©paration.
    - **entropy** : Utilise l'entropie pour √©valuer la puret√© des n≈ìuds de s√©paration.
    - **log_loss** : Sp√©cifique aux probl√®mes de classification multi-classes et mesure l'erreur de logarithme.                   

- **`max_depth`** : Profondeur maximale de chaque arbre dans l'ensemble. Une profondeur plus grande permet au mod√®le de capturer des relations plus complexes dans les donn√©es, mais peut conduire √† un surajustement si elle n'est pas r√©gularis√©e.
- **`min_samples_split`** : Nombre minimum d'√©chantillons requis pour scinder un n≈ìud interne. Cela r√©gule la croissance de l'arbre en imposant des contraintes sur le nombre d'observations n√©cessaires pour former une nouvelle division.
- **`min_samples_leaf`** : le nombre minimum d'√©chantillons qu'un n≈ìud terminal (ou feuille) doit contenir. Cela aide √† emp√™cher la cr√©ation de n≈ìuds avec tr√®s peu d'√©chantillons, ce qui pourrait conduire √† un mod√®le surajust√©.
- **`n_estimators`** : Nombre d'arbres dans l'ensemble. Un nombre plus √©lev√© d'arbres peut am√©liorer les performances du mod√®le, mais cela n√©cessite √©galement plus de temps de calcul.
- **`max_features`** : Nombre maximum de caract√©ristiques √† consid√©rer lors de la recherche de la meilleure division. Limiter le nombre de caract√©ristiques peut aider √† r√©duire la variance et le temps de calcul, en particulier dans les ensembles de donn√©es avec de nombreuses fonctionnalit√©s.
- **`class_weight`** : Fa√ßon de traiter les d√©s√©quilibres de classe en donnant plus de poids aux classes moins fr√©quentes.
  - **balanced** : Ajuste automatiquement les poids des classes invers√©ment proportionnels √† leur fr√©quence.
  - **balanced_subsample** : Fonctionne de la m√™me mani√®re que 'balanced', mais ajuste √©galement les poids √† chaque √©chantillon d'arbre, plut√¥t qu'√† l'ensemble de donn√©es global.
"""


# S√©lection du mod√®le via liste d√©roulante
model_choice = st.selectbox(
    label='S√©lectionner un mod√®le',
    options=['Gradient Boosting Classifier', 'Random Forest Classifier'], 
    index=None,  # Assurez-vous √©galement que l'index est valide, 0 pour s√©lectionner le premier √©l√©ment
    placeholder="Mod√®le . . .")  # Masquer le label tout en restant accessible


# D√©finition des mod√®les avant et apr√®s optimisation en fonction du choix de l'utilisateur
if model_choice:
    model_after = gbc_after if model_choice == 'Gradient Boosting Classifier' else rfc_after
    model_before = gbc_before if model_choice == 'Gradient Boosting Classifier' else rfc_before

    # Description du mod√®le
    with st.expander("Description du Mod√®le"):
        display_model_analysis(model_before, model_choice, description=True)
    
    # Param√®tres du mod√®le
    with st.expander("Optimisation des hyperparam√®tres du Mod√®le"):
        
        if st.checkbox("Pr√©sentation des hyperparam√®tres utilis√©s", key='checkbox13'):
            st.write("""
<p style='font-size:18px'>Hyperparam√®tres du mod√®le <strong>{}</strong></p>
""".format(model_choice), unsafe_allow_html=True) 
            if model_choice == 'Gradient Boosting Classifier':
                st.markdown(description_hyper_gbc)
            else:
                st.markdown(description_hyper_rfc)
           
                
        if st.checkbox("Application de GridSearchCV()", key='checkbox11'):
            st.write("""
**`GridSearchCV est une technique d'optimisation des hyperparam√®tres qui effectue une recherche exhaustive sur un espace de param√®tres sp√©cifi√©. 
Elle utilise la validation crois√©e pour √©valuer les performances de chaque combinaison de param√®tres sur les donn√©es d'entrainement`**
""")        
            st.write("""
<p style='font-size:16px'>Grille des hyperparam√®tres pour le mod√®le <strong>{}</strong></p>
""".format(model_choice), unsafe_allow_html=True) 

            if model_choice == 'Gradient Boosting Classifier':
                st.table(gbc_param_grid_df)
            else:
                st.table(rfc_param_grid_df)
   
        
        if st.checkbox("Valeurs des Param√®tres avant et apr√®s optimisation", key='checkbox12'):
            
            # Create two columns to display the model parameters
            col_before, col_after = st.columns(2)

            if model_choice == 'Gradient Boosting Classifier':
                with col_before:
                    st.write("""
        <p style='font-size:16px'><strong>Gradient Boosting Classifier par d√©faut<strong></p>
        """, unsafe_allow_html=True) 
                    st.table(params_gbc_before_df)

                with col_after:
                    st.write("""
        <p style='font-size:16px'><strong>Gradient Boosting Classifier Optimis√©<strong></p>
        """, unsafe_allow_html=True) 
                    st.table(params_gbc_after_df)
            
            else:
  
                with col_before:
                    st.write("""
        <p style='font-size:16px'><strong>Random Forest Classifier par d√©faut<strong></p>
        """, unsafe_allow_html=True) 
                    st.table(params_rfc_before_df)

                with col_after:
                    st.write("""
        <p style='font-size:16px'><strong>Random Forest Classifier Optimis√©<strong></p>
        """, unsafe_allow_html=True) 
                    st.table(params_rfc_after_df)
       
        
    # Performance du mod√®le avant et apr√®s optimisation
    
    with st.expander("Performance du Mod√®le avant et apr√®s optimisation des hyperparam√®tres"):
        st.write("""
<p style='font-size:16px'>Mod√®le <strong>{}</strong></p>
""".format(model_choice), unsafe_allow_html=True) 
        col1, col2 = st.columns(2)
        with col1:
            display_model_analysis(model_before, "Mod√®le par d√©faut", performance=True)
        with col2:
            display_model_analysis(model_after, "Mod√®le optimis√©", performance=True)

        y_scores_before = model_before.predict_proba(X_test)[:, 1]
        y_scores_after = model_after.predict_proba(X_test)[:, 1]
        fpr_before, tpr_before, _ = roc_curve(y_test, y_scores_before)
        fpr_after, tpr_after, _ = roc_curve(y_test, y_scores_after)
        
        fig, ax = plt.subplots()
        ax.plot(fpr_before, tpr_before, label=f'ROC Mod√®le par d√©faut (AUC = {roc_auc_score(y_test, y_scores_before):.2f})', color='lightcoral')
        ax.plot(fpr_after, tpr_after, label=f'ROC Mod√®le optimis√© (AUC = {roc_auc_score(y_test, y_scores_after):.2f})', color='lightblue')
        ax.set_title('Comparaison des Courbes ROC', fontsize=10, fontname='Arial', color='black')
        ax.set_xlabel('Taux de Faux Positifs', fontsize=9, fontname='Arial', color='black')
        ax.set_ylabel('Taux de Vrais Positifs', fontsize=9, fontname='Arial', color='black')
        ax.legend(loc='lower right')
        ax.grid(True)
        
        # D√©finir les couleurs de fond et ajuster d'autres styles
        ax.set_facecolor('none')  # Correspond √† plot_bgcolor='rgba(0,0,0,0)'
        fig.patch.set_facecolor('none')  # Correspond √† paper_bgcolor='rgba(0,0,0,0)'
        
        # Afficher le graphique dans Streamlit
        st.pyplot(fig, use_container_width=True)

    
# ------------------------------------------------------------------------------------------------
# bouton de basculement de page 
#CSS pour que les boutons de la page (et surtout mod√©lisation ) soient de la m√™me largeur
st.markdown("""
    <style>
    .stButton button {
        width: 40%;
    }
    </style>
""", unsafe_allow_html=True)
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
if st.button("‚ñ∂Ô∏è\u2003 üí°Interpr√©tation_des_mod√®les"):
    st.switch_page("pages/5_üí°_Interpr√©tation_des_mod√®les.py")
    

# ------------------------------------------------------------------------------------------------
