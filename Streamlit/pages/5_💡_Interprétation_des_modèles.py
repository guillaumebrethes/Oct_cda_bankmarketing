import streamlit as st  # type: ignore
import pandas as pd
import numpy as np
import joblib # type: ignore
import matplotlib.pyplot as plt
from streamlit_shap import st_shap # type: ignore
import shap # type: ignore
import plotly.graph_objects as go # type: ignore

# Page
st.set_page_config(
    page_title="Bank Marketing",
    page_icon="üí°", 
    #layout="wide" 
)

# CSS - - - - - 
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
local_css("styles.css")
# - - - - - - - 

# titre
st.markdown('<h1 class="custom-title">Interpr√©tation des mod√®les</h1>', unsafe_allow_html=True)

if st.button("‚óÄÔ∏è\u2003‚öôÔ∏è Modelisation"):
    st.switch_page("pages/4_‚öôÔ∏è_Modelisation.py")
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.markdown(
    """ 
    Introduction √† ecrire  Estelle
    """
    )

# --------------------------------------------------------------------------------------------
# Importation des jeux d'entrainement et de test sauvegard√©s  depuis google collab
X_test = pd.read_csv("Split_csv/3_bank_X_test.csv",index_col=0)
y_test = pd.read_csv("Split_csv/3_bank_y_test.csv",index_col=0)
X_test_copie = pd.read_csv("Split_csv/3_bank_X_test_copie.csv",index_col=0)

#Importation des valeurs Shap (que la classe 1 pour rfc)
shap_values_gbc = np.load('Shap/shap_values_gbc.npy')
shap_values_rfc = np.load('Shap/shap_values_rfc.npy')

# importations des mod√®les optimis√©s √† interpr√©ter
gbc_after = joblib.load("Models/model_gbc_after")
rfc_after = joblib.load("Models/model_rfc_after")
# --------------------------------------------------------------------------------------------

st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.write("### Interpr√©tation des Mod√®les avec la m√©thode SHAP ###")
# st.markdown('<h1 style="font-size: 30px;">Interpr√©tation des Mod√®les avec la m√©thode SHAP</h1>', unsafe_allow_html=True)

#---------------------------------------
#Cr√©ation d'un expander pour expliquer la m√©thode Shap

with st.expander("Cliquez ici pour en savoir plus sur la m√©thode SHAP"):

    st.markdown("""
    <div class="explain_shap">
        La m√©thode SHAP (SHapley Additive exPlanations) repose sur les valeurs de Shapley, une m√©thode issue de la th√©orie des jeux coop√©ratifs, pour attribuer √† chaque caract√©ristique (ou variable) une importance en fonction de sa contribution √† la pr√©diction.
        <br><br>
        SHAP est une m√©thode qui explique comment les pr√©dictions individuelles sont effectu√©es par un mod√®le d'apprentissage automatique. Elle d√©construit une pr√©diction en une somme de contributions (valeurs SHAP) de chacune des variables d'entr√©e du mod√®le.
        <br><br>
        √Ä noter que SHAP indique ce que fait le mod√®le dans le contexte des donn√©es sur lesquelles il a √©t√© form√©. Il ne r√©v√®le pas n√©cessairement la v√©ritable relation entre les variables et les r√©sultats dans le monde r√©el.
    </div>
    """, unsafe_allow_html=True)
    
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
#----------------------------------------------------------------------------------------------------------------------
#On propose de voir la page en fonction du mod√®le s√©l√©ctionn√© gbc_after ou rfc_after

st.markdown("""
Bienvenue dans cette application d'analyse des mod√®les ! Vous pouvez s√©lectionner un mod√®le dans la liste d√©roulante ci-dessous pour visualiser les 10 variables les plus importantes.
""")

# S√©lection du mod√®le via liste d√©roulante
model_choice = st.selectbox(
    label='',
    options=['Gradiant Boosting Classifier', 'Random Forest Classifier'], 
    index=None, 
    placeholder="Mod√®le . . .")
# ------------------------------------------

# Graphique d'importance des variables
if model_choice:
    model = gbc_after if model_choice == 'Gradiant Boosting Classifier' else rfc_after
    shap_values = shap_values_gbc if model_choice == 'Gradiant Boosting Classifier' else shap_values_rfc
    expected_value = shap.TreeExplainer(gbc_after).expected_value \
    if model_choice == 'Gradiant Boosting Classifier'\
        else shap.TreeExplainer(rfc_after).expected_value[1]

    plt.figure() 
    shap.summary_plot(shap_values, 
                      X_test, 
                      plot_type="bar", 
                      max_display=10, 
                      show=False)
    st.pyplot(plt.gcf(), use_container_width=True)

    st.markdown(
        """
        L'axe des X repr√©sente la moyenne des valeurs SHAP absolues pour chaque variable, indiquant l'importance moyenne de chaque variable sur la pr√©diction du mod√®le. **duration est la variable qui influence le plus la pr√©diction du mod√®le**
        """)

# Utilisation d'un extender pour montrer le Graphique d'importance des variables     
    with st.expander("üîç **Impact des variables dans la d√©cision du mod√®le**"):
        plt.figure() 
        shap.summary_plot(shap_values, 
                          X_test, 
                          max_display=10, 
                          show=False)
        st.pyplot(plt.gcf(), use_container_width=True)
         
        st.markdown(
            """
            Dans ce graphique, l'axe des x repr√©sente la valeur SHAP et l'axe des y repr√©sente les variables explicatives (ici le TOP 10). Chaque point du graphique correspond √† une valeur SHAP pour une pr√©diction et une variable explicative. 
            
            La couleur rouge signifie une valeur plus √©lev√©e de la variable explicative. Le bleu signifie une valeur faible de cette derni√®re. Nous pouvons avoir une id√©e g√©n√©rale de la directionnalit√© de l'impact des variables en fonction de la distribution des points rouges et bleus. 
            
            
            On peut lire que plus la valeur de **duration** est grande (le temps de l'appel long), plus l'impact sur la pr√©diction de souscription du d√©p√¥t √† terme est positif  et inversement plus **duration** est faible, plus l'impact sur la pr√©diction est n√©gatif.
            
            Une valeur importante de **poutcome_success** (client avait souscrit √† un d√©p√¥t √† terme auparavant) a un impact positif sur la souscription du d√©p√¥t √† terme.
            
            Une valeur plus grande de de **housing** (le client a un pr√™t immobilier) a un impact n√©gatif sur la pr√©diction de la souscription du d√©p√¥t et inversement une valeur faible ( le client n‚Äôa pas de pr√™t immobilier) a un effet positif sur la pr√©diction de la souscription du d√©p√¥t.
            """
            )

#---------------------------------------
# Utilisation d'un extender pour montrer les predictions et shap values par individu
    with st.expander("üîç **Visualisation des pr√©dictions individuelles du jeux de donn√©es Test**"):
    
    # Choix de l'index par l'utilisateur 743 est cool
        index_to_show = st.slider('Choisissez l\'index de l\'observation √† visualiser', 0, len(X_test) - 1, 0, 
                              help = "les cases coch√©es repr√©sentent le mois, le job, le poutcome du client selectionn√©")

    # Cr√©er un objet Explanationx
        shap_values_instance = shap.Explanation(
            values=shap_values[index_to_show],
            base_values=expected_value,
            data=X_test.iloc[index_to_show]  # Inclure les donn√©es d'entr√©e pour plus de contexte dans le plot
    )

    #Afficher les informations du DataFrame pour cet infividu
        st.dataframe(X_test_copie.iloc[[index_to_show]])

    # Afficher (y_test) ---
        if y_test.iloc[index_to_show].item()== 1:
            deposit = "**a souscrit au d√©p√¥t √† terme**"
        else:
            deposit = "**n'a pas souscrit au d√©p√¥t √† terme**"
        st.markdown(f"**D√©cision r√©elle du client** : Cet individu {deposit}")
    # ---
    
    # Afficher ((y_pred) ---
        y_pred = model.predict(X_test.iloc[[index_to_show]])
        if y_pred.item() == 1:
           deposit_pred = " **souscrira au d√©p√¥t √† terme**"
        else:
            deposit_pred = "**ne souscrira pas au d√©p√¥t √† terme**"
        st.markdown(f"**Pr√©diction du mod√®le** : Ce mod√®le pr√©dit que cet individu {deposit_pred}")
    # ---

    #Afficher les valeurs shap (top 10 pour cet individu)
        st.markdown(' **Waterfall plot** pour cet individu : ')
    
    # Create a figure 
        fig, ax = plt.subplots()

    # Generate the waterfall plot on the created figure
        shap.plots.waterfall(shap_values_instance, max_display=10, show=False)  

    # Display the plot in Streamlit
        st.pyplot(fig)

   #Explications de lecture du graphique
   
        st.markdown(
        """
        La structure en cascade illustre comment les contributions additives des variables explicatives, qu'elles soient positives ou n√©gatives, s'accumulent √† partir d'une valeur de base (E[f(X)]). 
        
        Cette accumulation met en √©vidence comment chaque variable explicative construit progressivement la pr√©diction finale du mod√®le, not√©e f(x).
        """
        ) 

#---------------------------------------

    with st.expander("üîç **Impact des variables dans la pr√©diction en fonction de leur valeur**"):
    
        st.markdown("Grace au **Dependance plot** on peut visualiser et comprendre comment des valeurs sp√©cifiques d'une variable influencent les pr√©dictions du mod√®le.")
   
    # Case √† cocher pour le  graphique
        if st.checkbox("Dependance Plot **duration**", key='checkbox5'):
            plt.figure()
            shap.dependence_plot('duration', shap_values, X_test_copie, interaction_index=None)
            st.pyplot(plt)
            st.markdown("‚Ä¢ On peut voir √† partir de quelle valeur de **duration** l'impact sur la pr√©diction devient positif")
        
    # Case √† cocher pour le  graphique
        if st.checkbox("Dependance Plot **balance**", key='checkbox6'):
            st.markdown("**balance** est le solde moyen annuel sur le compte courant")
            plt.figure()
            shap.dependence_plot('balance', shap_values, X_test_copie, interaction_index=None)
            st.pyplot(plt)
            st.markdown("‚Ä¢ On peut voir √† partir de quelle valeur de **balance** l'impact sur la pr√©diction devient positif")
        
    # Case √† cocher pour le  graphique
        if st.checkbox("Dependance Plot **age**", key='checkbox7'):
            plt.figure()
            shap.dependence_plot('age', shap_values, X_test_copie, interaction_index=None)
            st.pyplot(plt)
            st.markdown("‚Ä¢ On peut voir les **ages** pour lesquels l'impact sur la pr√©diction est positif et ceux pour lesquels l'impact est n√©gatif")
        
    # Case √† cocher pour le  graphique
        if st.checkbox("Dependance Plot **campaign**", key='checkbox8'):
            st.markdown("**campaign** est le nombre de contacts effectu√©s sur la campagne")
            plt.figure()
            shap.dependence_plot('campaign', shap_values, X_test_copie, interaction_index=None)
            st.pyplot(plt)        
            st.markdown("‚Ä¢ On peut voir que s'il y a plus d'1 contact, **campaign** a un impact n√©gatif sur la pr√©vision")
            


# ------------------------------------------------------------------------------------------------
# bouton de basculement de page 
st.write("   ")
st.markdown('<hr class="my_custom_hr">', unsafe_allow_html=True)
st.write("   ")

if st.button("‚ñ∂Ô∏è\u2003 üéØ Recommandation m√©tier - Conclusion"):
    st.switch_page("pages/6_üéØ_Recommandation_m√©tier_-_Conclusion.py")
    

# ------------------------------------------------------------------------------------------------
